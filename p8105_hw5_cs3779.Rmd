---
title: "p8105_hw5_cs3779"
author: "CJ Snyder"
date: "11/7/2019"
output: github_document
---

```{r, include = FALSE}
library(tidyverse)
library(knitr)
library(readxl)
library(viridis)
library(patchwork)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# **Problem 1**
## **Uploading Iris Dataset**
```{r}
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

kable(iris_with_missing)
```

## **Creating Function to Replace Missing Values in Iris Dataset**
```{r}
replace_missing = function(x) {
  if (is.numeric(x)) {
    x = round(replace_na(x, mean(x, na.rm = TRUE)), digits = 1)
  }
  else if (is.character(x)) {
    (x = replace_na(x, "virginica"))
  }
}

output = vector("list", length = 5)

for (i in 1:5) {
  output[[i]] = replace_missing(iris_with_missing[[i]])
}

iris_with_missing = map_df(.x = iris_with_missing, ~replace_missing(.x))

kable(iris_with_missing)
```

# **Problem 2**
## **Reading and Tidying Experimental Dataset**
```{r}
prob2_df = list.files(path = "./data", pattern = "*.csv", full.names = T) %>% 
    map_dfr(~read.csv(.)) %>% 
  mutate(
    treatment_arm = list.files(path="./data") %>% 
              word(sep="_")
  ) %>% 
  rownames_to_column(var = "subject_id") %>%
  mutate(
    treatment_arm = str_replace(treatment_arm, "con", "control"),
    treatment_arm = str_replace(treatment_arm, "exp", "treatment")
  ) %>% 
  select(subject_id, treatment_arm, week_1:week_8) %>%
  pivot_longer(
    cols = starts_with("week"),
    names_to = "week"
  )

prob2_plot = 
  ggplot(prob2_df, aes(x=week, y=value, group=subject_id, color=treatment_arm)) +
  geom_point() + geom_line()

prob2_plot
```

**Notes:** Comparing the treatment arm to the control arm at the beginning of the observation period, both groups started with around the same values, but by the end of the 8 week observation period (and starting around the 3 week period) the treatment arm had on average higher values than the control arm. 

# **Problem 3**
## **Simulating 10,000 Datasets**
```{r}
sim_slr = function(beta1) {
  
  sim_data = tibble(
    x = rnorm(30, mean = 0, sd = 1),
    y = 2 + beta1 * x + rnorm(30, 0, 7.07)
  )
  
  ls_fit = lm(y ~ x, data = sim_data)
   
  fit_stats = 
    ls_fit %>% 
    broom::tidy() %>% 
    select(term, estimate, p.value) %>% 
    filter(term=="x")
}

sim_repeat = function(x) {
  rerun(10000, sim_slr(x)) %>% 
    bind_rows()
}
```

## **Plotting Simulated Datasets**
```{r}
sim_results = 
  tibble(
    beta_list = c("beta = 0" = 0,
                 "beta = 1" = 1,
                 "beta = 2" = 2,
                 "beta = 3" = 3,
                 "beta = 4" = 4,
                 "beta = 5" = 5,
                 "beta = 6" = 6) 
  ) %>% 
  mutate(
    output_list = map(.x = beta_list, ~ sim_repeat(.x)),
    output_df = map(output_list, bind_rows)
  ) %>% 
  select(-output_list) %>% 
  unnest(output_df)

reject_prop = 
  sim_results %>% 
    filter(p.value<0.05) %>% 
    group_by(beta_list) %>% 
    summarize(n=n()) 

ggplot(reject_prop, aes(x=beta_list, y=n)) + geom_col() +
  labs(
    x = "Beta_1 Tested",
    y = "Number of times Null Hypothesis was Rejected"
  )
```

**Notes:** The bar graph shows that as the effect size increases, then power increases (i.e. the probability of correctly reject the null hypothesis). This can be seen by the fact that the number of times the null hypothesis (Beta = 0) was rejected drastically increased as the estimated beta increased in size.

```{r}
avg_beta = 
  sim_results %>% 
  filter(p.value<0.05) %>% 
  group_by(beta_list) %>% 
  mutate(
    avg_beta = mean(estimate)
  )

ggplot(avg_beta, aes(x=beta_list, y=avg_beta)) + geom_point() + geom_line() +
  labs(
    x = "Beta_1 Tested",
    y = "Average Estimated Beta per Beta_1 TestedGroup"
  )
```

**Notes:** Amongst the samples in which the null hypothesis was rejected, the average estimated beta across tests became closer to the true value of the beta as the value of the tested beta increased (i.e. the estimated and true values of beta are far apart for beta = 1, but are much closer when beta = 6). The reason for this is because larger effect sizes are easier to detect, and because of the large number of samples taken, the average estimate should be closer and closer to the population parameter. 







